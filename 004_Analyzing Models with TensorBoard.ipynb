{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4961b1f-dd16-4091-92f5-cd527d4aa287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 27ms/step - accuracy: 0.5491 - loss: 0.6800 - val_accuracy: 0.6924 - val_loss: 0.5965\n",
      "Epoch 2/7\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 27ms/step - accuracy: 0.6996 - loss: 0.5754 - val_accuracy: 0.7362 - val_loss: 0.5242\n",
      "Epoch 3/7\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 27ms/step - accuracy: 0.7648 - loss: 0.4915 - val_accuracy: 0.7521 - val_loss: 0.5143\n",
      "Epoch 4/7\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 27ms/step - accuracy: 0.7859 - loss: 0.4659 - val_accuracy: 0.7746 - val_loss: 0.4762\n",
      "Epoch 5/7\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 27ms/step - accuracy: 0.7996 - loss: 0.4377 - val_accuracy: 0.7619 - val_loss: 0.5036\n",
      "Epoch 6/7\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 27ms/step - accuracy: 0.8213 - loss: 0.4062 - val_accuracy: 0.7839 - val_loss: 0.4552\n",
      "Epoch 7/7\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 27ms/step - accuracy: 0.8287 - loss: 0.3820 - val_accuracy: 0.7751 - val_loss: 0.4724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b683d5e250>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "NAME = \"Cats-vs-dogs-CNN\"\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "\n",
    "\n",
    "# Carga los datos desde los archivos pickle\n",
    "# Abre el archivo \"X.pickle\" en modo lectura binaria\n",
    "pickle_in = open(\"X.pickle\", \"rb\")\n",
    "# Carga los datos de las imágenes desde el archivo y conviértelos a un array de numpy\n",
    "X = np.array(pickle.load(pickle_in))\n",
    "\n",
    "# Abre el archivo \"y.pickle\" en modo lectura binaria\n",
    "pickle_in = open(\"y.pickle\", \"rb\")\n",
    "# Carga las etiquetas de las imágenes desde el archivo y conviértelos a un array de numpy\n",
    "y = np.array(pickle.load(pickle_in))\n",
    "\n",
    "# Normaliza los datos\n",
    "# Divide cada valor de píxel por 255.0 para normalizar los datos de las imágenes a un rango [0, 1]\n",
    "X = X / 255.0\n",
    "\n",
    "# Construye el modelo\n",
    "model = Sequential()  # Inicializa un modelo secuencial\n",
    "\n",
    "# Añade una capa convolucional con 64 filtros y un tamaño de kernel de 3x3\n",
    "# Especifica la forma de entrada que corresponde a la de los datos de las imágenes\n",
    "model.add(Conv2D(64, (3, 3), input_shape=X.shape[1:]))\n",
    "model.add(Activation('relu'))  # Añade una función de activación ReLU\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  # Añade una capa de max-pooling con un tamaño de pool de 2x2\n",
    "\n",
    "# Añade una segunda capa convolucional con 64 filtros y un tamaño de kernel de 3x3\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))  # Añade una función de activación ReLU\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  # Añade una capa de max-pooling con un tamaño de pool de 2x2\n",
    "\n",
    "# Aplana las características 3D a un vector 1D\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "\n",
    "# Añade una capa densa con una unidad (salida)\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))  # Añade una función de activación sigmoide para la salida\n",
    "\n",
    "# Compila el modelo\n",
    "# Utiliza la pérdida de entropía cruzada binaria y el optimizador Adam\n",
    "# Mide la precisión durante el entrenamiento\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Entrena el modelo\n",
    "# Utiliza un tamaño de lote de 32 y entrena por 3 épocas\n",
    "# Usa el 30% de los datos para la validación durante el entrenamiento\n",
    "model.fit(X, y, batch_size=32, epochs=7, validation_split=0.3, callbacks= [tensorboard])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbe6dd9-39a6-4eb2-9882-20cd28002361",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1286b4a5-65b7-4b76-ba14-0bcdd76663cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-conv-64-nodes-0-dense-1717842622\n",
      "Epoch 1/7\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.5845 - loss: 0.6640 - val_accuracy: 0.7265 - val_loss: 0.5480\n",
      "Epoch 2/7\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 28ms/step - accuracy: 0.7439 - loss: 0.5218 - val_accuracy: 0.7602 - val_loss: 0.5067\n",
      "Epoch 3/7\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.7786 - loss: 0.4706 - val_accuracy: 0.7750 - val_loss: 0.4733\n",
      "Epoch 4/7\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 28ms/step - accuracy: 0.8033 - loss: 0.4336 - val_accuracy: 0.7918 - val_loss: 0.4367\n",
      "Epoch 5/7\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.8172 - loss: 0.3978 - val_accuracy: 0.8053 - val_loss: 0.4273\n",
      "Epoch 6/7\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 28ms/step - accuracy: 0.8420 - loss: 0.3542 - val_accuracy: 0.8002 - val_loss: 0.4167\n",
      "Epoch 7/7\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 29ms/step - accuracy: 0.8604 - loss: 0.3286 - val_accuracy: 0.8001 - val_loss: 0.4211\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Carga los datos desde los archivos pickle\n",
    "pickle_in = open(\"X.pickle\", \"rb\")\n",
    "X = np.array(pickle.load(pickle_in))\n",
    "\n",
    "pickle_in = open(\"y.pickle\", \"rb\")\n",
    "y = np.array(pickle.load(pickle_in))\n",
    "\n",
    "# Normaliza los datos\n",
    "X = X / 255.0\n",
    "\n",
    "dense_layers = [0]\n",
    "layer_sizes = [64]\n",
    "conv_layers = [3]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "            print(NAME)\n",
    "\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Conv2D(layer_size, (3, 3), input_shape=X.shape[1:]))\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            for l in range(conv_layer - 1):\n",
    "                model.add(Conv2D(layer_size, (3, 3)))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            model.add(Flatten())\n",
    "            for _ in range(dense_layer):\n",
    "                model.add(Dense(512))\n",
    "                model.add(Activation('relu'))\n",
    "\n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation('sigmoid'))\n",
    "\n",
    "            model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "            \n",
    "            model.fit(X, y, batch_size=32, epochs=7, validation_split=0.3, callbacks=[tensorboard])\n",
    "            \n",
    "model.save('64x3-CNN.keras')  # Cambiado a .keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ceeff411-a70f-4776-94cf-9cf6660aea4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "[[1.1833292e-29]]\n",
      "Dog\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "CATEGORIES = [\"Dog\", \"Cat\"]  # usarás esto para convertir el número de predicción en un valor de cadena\n",
    "\n",
    "def prepare(filepath):\n",
    "    IMG_SIZE = 75  # Cambiamos el tamaño de la imagen a 75x75\n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)  # Devolvemos la imagen con la forma (1, 75, 75, 1)\n",
    "\n",
    "model = tf.keras.models.load_model(\"64x3-CNN.keras\")\n",
    "prediction = model.predict(prepare('cat.jpg'))  # No es necesario pasar una lista\n",
    "print(prediction)\n",
    "\n",
    "# Interpretar el resultado\n",
    "print(CATEGORIES[int(prediction[0][0])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e2897f59-0e64-4794-8a7b-d9f3290ccfce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Dog\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict([prepare('cat.jpg')])\n",
    "print(CATEGORIES[int(prediction[0][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0ef15c56-09fc-4ad3-afcd-3a667d003add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Cat\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict([prepare('dog.jpg')])\n",
    "print(CATEGORIES[int(prediction[0][0])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe3b4fd-7360-4594-9f74-0db404c55884",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

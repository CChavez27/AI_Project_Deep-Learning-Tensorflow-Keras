{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1286b4a5-65b7-4b76-ba14-0bcdd76663cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-conv-64-nodes-0-dense-1718584567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CRISTIAN CHAVEZ\\Documents\\GitHub\\AI_Project_Deep-Learning-Tensorflow-Keras\\env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.5647 - loss: 0.6764 - val_accuracy: 0.6999 - val_loss: 0.5875\n",
      "Epoch 2/7\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.7081 - loss: 0.5613 - val_accuracy: 0.7460 - val_loss: 0.5177\n",
      "Epoch 3/7\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.7643 - loss: 0.4875 - val_accuracy: 0.7582 - val_loss: 0.4995\n",
      "Epoch 4/7\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7862 - loss: 0.4514 - val_accuracy: 0.7779 - val_loss: 0.4681\n",
      "Epoch 5/7\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.8056 - loss: 0.4217 - val_accuracy: 0.7737 - val_loss: 0.4768\n",
      "Epoch 6/7\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.8164 - loss: 0.4024 - val_accuracy: 0.8026 - val_loss: 0.4351\n",
      "Epoch 7/7\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.8375 - loss: 0.3686 - val_accuracy: 0.7990 - val_loss: 0.4376\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Carga los datos desde los archivos pickle\n",
    "pickle_in = open(\"X.pickle\", \"rb\")\n",
    "X = np.array(pickle.load(pickle_in))\n",
    "\n",
    "pickle_in = open(\"y.pickle\", \"rb\")\n",
    "y = np.array(pickle.load(pickle_in))\n",
    "\n",
    "# Normaliza los datos\n",
    "X = X / 255.0\n",
    "\n",
    "dense_layers = [0]\n",
    "layer_sizes = [64]\n",
    "conv_layers = [3]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "            print(NAME)\n",
    "\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Conv2D(layer_size, (3, 3), input_shape=X.shape[1:]))\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            for l in range(conv_layer - 1):\n",
    "                model.add(Conv2D(layer_size, (3, 3)))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            model.add(Flatten())\n",
    "            for _ in range(dense_layer):\n",
    "                model.add(Dense(512))\n",
    "                model.add(Activation('relu'))\n",
    "\n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation('sigmoid'))\n",
    "\n",
    "            model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "            \n",
    "            model.fit(X, y, batch_size=32, epochs=7, validation_split=0.3, callbacks=[tensorboard])\n",
    "            \n",
    "model.save('64x3-CNN.keras')  # Cambiado a .keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ceeff411-a70f-4776-94cf-9cf6660aea4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "[[0.00143422]]\n",
      "Dog\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "CATEGORIES = [\"Dog\", \"Cat\"]  # Lista de categorías, se usará para convertir el número de predicción en una etiqueta de cadena\n",
    "\n",
    "def preparar_imagen(filepath):\n",
    "    IMG_SIZE = 50  # Tamaño al que se redimensionará la imagen (50x50 en este caso)\n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)  # Cargar la imagen en escala de grises\n",
    "    \n",
    "    # Verificar si la imagen se cargó correctamente\n",
    "    if img_array is None:\n",
    "        raise ValueError(\"Error: No se pudo cargar la imagen. Verifica la ruta de la imagen.\")\n",
    "    \n",
    "    # Redimensionar la imagen manteniendo la relación de aspecto original\n",
    "    aspect_ratio = img_array.shape[1] / img_array.shape[0]\n",
    "    if aspect_ratio > 1:  # Si la imagen es más ancha que alta\n",
    "        new_width = IMG_SIZE\n",
    "        new_height = int(IMG_SIZE / aspect_ratio)\n",
    "    else:  # Si la imagen es más alta que ancha o cuadrada\n",
    "        new_height = IMG_SIZE\n",
    "        new_width = int(IMG_SIZE * aspect_ratio)\n",
    "    resized_img = cv2.resize(img_array, (new_width, new_height))\n",
    "    \n",
    "    # Rellenar o recortar la imagen para que sea de tamaño 50x50\n",
    "    padded_img = np.zeros((IMG_SIZE, IMG_SIZE), dtype=np.uint8)\n",
    "    if aspect_ratio > 1:  # Si la imagen es más ancha que alta\n",
    "        start_y = (IMG_SIZE - new_height) // 2\n",
    "        padded_img[start_y:start_y + new_height, :] = resized_img\n",
    "    else:  # Si la imagen es más alta que ancha o cuadrada\n",
    "        start_x = (IMG_SIZE - new_width) // 2\n",
    "        padded_img[:, start_x:start_x + new_width] = resized_img\n",
    "    \n",
    "    # Normalizar la imagen\n",
    "    padded_img = padded_img / 255.0  # Escalar los valores de píxeles al rango [0, 1]\n",
    "    padded_img = padded_img.astype('float32')  # Asegurar que los valores sean de tipo float32\n",
    "    \n",
    "    return padded_img.reshape(1, IMG_SIZE, IMG_SIZE, 1)  # Devolver la imagen con la forma (1, 50, 50, 1)\n",
    "\n",
    "# Cargar el modelo pre-entrenado\n",
    "modelo = tf.keras.models.load_model(\"C:\\\\Users\\\\CRISTIAN CHAVEZ\\\\Documents\\\\GitHub\\\\AI_Project_Deep-Learning-Tensorflow-Keras\\\\64x3-CNN.keras\")\n",
    "\n",
    "# Realizar una predicción en una imagen\n",
    "prediction = modelo.predict(preparar_imagen('C:\\\\Users\\\\CRISTIAN CHAVEZ\\\\Documents\\\\GitHub\\\\AI_Project_Deep-Learning-Tensorflow-Keras\\\\IMG\\\\pato.jpg'))\n",
    "\n",
    "# Imprimir la predicción\n",
    "print(prediction)  # Esto será una lista dentro de otra lista\n",
    "category_index = int(prediction[0][0] >= 0.5)  # Usar el umbral 0.5 para determinar la categoría\n",
    "print(CATEGORIES[category_index])  # Convertir la predicción en una etiqueta y mostrarla\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

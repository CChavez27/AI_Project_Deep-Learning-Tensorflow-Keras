{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1160fca3-4841-4000-a9ab-2774d4e258ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTC\n",
      "DOGE\n",
      "ETH\n",
      "QTU\n",
      "            BTC_close  BTC_volume  DOGE_close  DOGE_volume  ETH_close  \\\n",
      "time                                                                    \n",
      "1715356800    60793.4      15.101    0.144841     169877.0    2914.04   \n",
      "1715356860    60729.3       6.395    0.144513     245666.0    2907.25   \n",
      "1715356920    60744.5       7.272    0.144437     417310.0    2906.65   \n",
      "1715356980    60713.9       4.568    0.144207     311595.0    2904.65   \n",
      "1715357040    60683.8      18.586    0.144067     153653.0    2901.04   \n",
      "\n",
      "            ETH_volume  QTU_close  QTU_volume  \n",
      "time                                           \n",
      "1715356800        45.7      3.629      1283.8  \n",
      "1715356860        23.8      3.620        44.7  \n",
      "1715356920       997.9      3.611        20.8  \n",
      "1715356980        82.0      3.606        46.6  \n",
      "1715357040        96.0      3.609        32.8  \n",
      "            DOGE_close    future\n",
      "time                            \n",
      "1715356800    0.144841  0.144547\n",
      "1715356860    0.144513  0.144578\n",
      "1715356920    0.144437  0.144634\n",
      "1715356980    0.144207  0.144473\n",
      "1715357040    0.144067  0.145137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CRISTIAN CHAVEZ\\AppData\\Local\\Temp\\ipykernel_33564\\3084470778.py:87: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  main_df.fillna(method=\"ffill\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn import preprocessing  # pip install sklearn\n",
    "from collections import deque\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Longitud de la secuencia precedente para recolectar para la RNN\n",
    "SEQ_LEN = 60\n",
    "\n",
    "# Cuánto tiempo en el futuro estamos tratando de predecir\n",
    "FUTURE_PERIOD_PREDICT = 8\n",
    "\n",
    "# El ratio que queremos predecir\n",
    "RATIO_TO_PREDICT = \"DOGE\"\n",
    "\n",
    "# Función para clasificar si el valor futuro es mayor que el valor actual\n",
    "def classify(current, future):\n",
    "    if float(future) > float(current):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Función para preprocesar el DataFrame\n",
    "def preprocess_df(df):\n",
    "    df = df.drop(columns=[\"future\"])  # ya no la necesitamos.\n",
    "\n",
    "    for col in df.columns:  # recorrer todas las columnas\n",
    "        if col != \"target\":  # normalizar todas excepto la columna objetivo\n",
    "            df[col] = df[col].pct_change()  # cambio porcentual \"normaliza\" las diferentes monedas (cada criptomoneda tiene valores muy diferentes, estamos más interesados en los movimientos de otras monedas)\n",
    "            df.dropna(inplace=True)  # eliminar los valores nulos creados por pct_change\n",
    "            df[col] = preprocessing.scale(df[col].values)  # escalar entre 0 y 1.\n",
    "\n",
    "    df.dropna(inplace=True)  # limpieza adicional... por si acaso. Esos molestos NaNs tienden a colarse.\n",
    "    sequential_data = []  # esta es una lista que CONTENDRÁ las secuencias\n",
    "    prev_days = deque(maxlen=SEQ_LEN)  # Estas serán nuestras secuencias reales. Se hacen con deque, que mantiene la longitud máxima eliminando los valores más antiguos a medida que entran nuevos.\n",
    "\n",
    "    for i in df.values:  # iterar sobre los valores\n",
    "        prev_days.append([n for n in i[:-1]])  # almacenar todo excepto el objetivo\n",
    "        if len(prev_days) == SEQ_LEN:  # asegurarse de tener 60 secuencias\n",
    "            sequential_data.append([np.array(prev_days), i[-1]])  # agregar esas secuencias!\n",
    "\n",
    "    random.shuffle(sequential_data)  # mezclar por buena medida\n",
    "\n",
    "# Uso de una cadena sin procesar para evitar errores de escape de unicode\n",
    "file_path = r\"C:\\Users\\CRISTIAN CHAVEZ\\Documents\\GitHub\\AI_Project_Deep-Learning-Tensorflow-Keras\\Modelo Para Predecir Criptomonedas\\criptodata\\DOGE.xlsx\"\n",
    "\n",
    "# Leer el archivo inicial\n",
    "df = pd.read_excel(file_path, names=['time', 'open', 'high', 'low', 'close', 'volume', 'usdVolume'])\n",
    "\n",
    "# DataFrame principal vacío para almacenar todos los datos\n",
    "main_df = pd.DataFrame()\n",
    "\n",
    "# Las 4 criptomonedas que queremos considerar\n",
    "ratios = [\"BTC\", \"DOGE\", \"ETH\", \"QTU\"]\n",
    "\n",
    "# Ruta base donde se encuentran los archivos de datos\n",
    "base_path = r\"C:\\Users\\CRISTIAN CHAVEZ\\Documents\\GitHub\\AI_Project_Deep-Learning-Tensorflow-Keras\\Modelo Para Predecir Criptomonedas\\criptodata\"\n",
    "\n",
    "# Iterar sobre cada ratio\n",
    "for ratio in ratios:\n",
    "    print(ratio)\n",
    "    \n",
    "    # Obtener la ruta completa al archivo\n",
    "    dataset = os.path.join(base_path, f\"{ratio}.xlsx\")\n",
    "    \n",
    "    # Leer el archivo específico\n",
    "    df = pd.read_excel(dataset, names=['time', 'open', 'high', 'low', 'close', 'volume', 'usdVolume'])\n",
    "    \n",
    "    # Renombrar columnas de 'close' y 'volume' para incluir el ticker\n",
    "    df.rename(columns={\"close\": f\"{ratio}_close\", \"volume\": f\"{ratio}_volume\"}, inplace=True)\n",
    "    \n",
    "    # Establecer 'time' como índice para poder unirlos por este tiempo compartido\n",
    "    df.set_index(\"time\", inplace=True)\n",
    "    \n",
    "    # Ignorar otras columnas además de 'close' y 'volume'\n",
    "    df = df[[f\"{ratio}_close\", f\"{ratio}_volume\"]]\n",
    "    \n",
    "    # Si el DataFrame principal está vacío, simplemente asignar el DataFrame actual\n",
    "    if len(main_df) == 0:\n",
    "        main_df = df\n",
    "    else:\n",
    "        # De lo contrario, unir estos datos con el DataFrame principal\n",
    "        main_df = main_df.join(df)\n",
    "\n",
    "# Si hay huecos en los datos, usar los valores conocidos anteriormente\n",
    "main_df.fillna(method=\"ffill\", inplace=True)\n",
    "# Eliminar filas con valores nulos\n",
    "main_df.dropna(inplace=True)\n",
    "\n",
    "# Imprimir las primeras filas del DataFrame resultante para verificar los datos\n",
    "print(main_df.head())\n",
    "\n",
    "# Crear una nueva columna 'future' que es el valor de cierre futuro desplazado por 'FUTURE_PERIOD_PREDICT'\n",
    "main_df['future'] = main_df[f'{RATIO_TO_PREDICT}_close'].shift(-FUTURE_PERIOD_PREDICT)\n",
    "\n",
    "# Crear una columna 'target' que clasifica si el valor futuro es mayor que el valor actual\n",
    "main_df['target'] = list(map(classify, main_df[f'{RATIO_TO_PREDICT}_close'], main_df['future']))\n",
    "\n",
    "# Imprimir las primeras filas del DataFrame resultante para verificar las nuevas columnas\n",
    "print(main_df[[f\"{RATIO_TO_PREDICT}_close\", \"future\"]].head())\n",
    "#print(main_df.head())  # Imprimir las primeras filas del DataFrame resultante para verificar la estructura y los datos cargados correctamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d3d8e24-832b-46a7-956e-46981146ca44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1715438880\n"
     ]
    }
   ],
   "source": [
    "# Obtener una lista ordenada de los valores del índice (los tiempos)\n",
    "times = sorted(main_df.index.values)\n",
    "\n",
    "# Calcular el punto de corte para el último 5% de los tiempos\n",
    "last_5pct = sorted(main_df.index.values)[-int(0.05 * len(times))]\n",
    "\n",
    "# Imprimir el valor del tiempo que representa el inicio del último 5% del conjunto de datos\n",
    "print(last_5pct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a8a78c8-0ce9-4448-b501-aa8057adee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el DataFrame de validación con los datos donde el índice está en el último 5% de los tiempos\n",
    "validation_main_df = main_df[(main_df.index >= last_5pct)]  # crear los datos de validación donde el índice está en el último 5%\n",
    "# Actualizar el DataFrame principal para que contenga solo los datos hasta el último 5%\n",
    "main_df = main_df[(main_df.index < last_5pct)]  # ahora el DataFrame principal contiene todos los datos hasta el último 5%\n",
    "\n",
    "# Preprocesar los datos principales\n",
    "preprocess_df(main_df)  # llamar a la función de preprocesamiento para los datos principales\n",
    "#train_x, train_y = preprocess_df(main_df) \n",
    "#validation_x, validation_y = preprocess_df(validation_main_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

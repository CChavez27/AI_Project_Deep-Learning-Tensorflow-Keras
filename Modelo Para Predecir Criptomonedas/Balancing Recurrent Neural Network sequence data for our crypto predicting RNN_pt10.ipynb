{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b563d716-d945-4123-904f-c34579e7f711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCH-USD\n",
      "BTC-USD\n",
      "ETH-USD\n",
      "LTC-USD\n",
      "1534892940\n",
      "train data: 79774 validation: 4042\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn import preprocessing  # pip install sklearn ... if you don't have it!\n",
    "from collections import deque\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Longitud de la secuencia precedente para recolectar para la RNN\n",
    "SEQ_LEN = 60\n",
    "\n",
    "# Cuánto tiempo en el futuro estamos tratando de predecir\n",
    "FUTURE_PERIOD_PREDICT = 8\n",
    "\n",
    "# El ratio que queremos predecir\n",
    "RATIO_TO_PREDICT = \"BTC-USD\"\n",
    "\n",
    "# Función para clasificar si el valor futuro es mayor que el valor actual\n",
    "def classify(current, future):\n",
    "    if float(future) > float(current):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def preprocess_df(df):\n",
    "    df = df.drop([\"future\"], axis=1)\n",
    "\n",
    "    for col in df.columns:  # go through all of the columns\n",
    "        if col != \"target\":  # normalize all ... except for the target itself!\n",
    "            df[col] = df[col].pct_change()  # pct change \"normalizes\" the different currencies (each crypto coin has vastly diff values, we're really more interested in the other coin's movements)\n",
    "            df.dropna(inplace=True)  # remove the nas created by pct_change\n",
    "            df[col] = preprocessing.scale(df[col].values)  # scale between 0 and 1.\n",
    "\n",
    "    df.dropna(inplace=True)  # cleanup again... jic. Those nasty NaNs love to creep in.\n",
    "    sequential_data = []  # this is a list that will CONTAIN the sequences\n",
    "    prev_days = deque(maxlen=SEQ_LEN)  # These will be our actual sequences. They are made with deque, which keeps the maximum length by popping out older values as new ones come in\n",
    "\n",
    "    for i in df.values:  # iterate over the values\n",
    "        prev_days.append([n for n in i[:-1]])  # store all but the target\n",
    "        if len(prev_days) == SEQ_LEN:  # make sure we have 60 sequences!\n",
    "            sequential_data.append([np.array(prev_days), i[-1]])  # append those bad boys!\n",
    "\n",
    "    random.shuffle(sequential_data)  # shuffle for good measure.\n",
    "    \n",
    "    buys = []  # list that will store our buy sequences and targets\n",
    "    sells = []  # list that will store our sell sequences and targets\n",
    "\n",
    "    for seq, target in sequential_data:  # iterate over the sequential data\n",
    "        if target == 0:  # if it's a \"not buy\"\n",
    "            sells.append([seq, target])  # append to sells list\n",
    "        elif target == 1:  # otherwise if the target is a 1...\n",
    "            buys.append([seq, target])  # it's a buy!\n",
    "\n",
    "    random.shuffle(buys)  # shuffle the buys\n",
    "    random.shuffle(sells)  # shuffle the sells!\n",
    "\n",
    "    lower = min(len(buys), len(sells))  # what's the shorter length?\n",
    "\n",
    "    buys = buys[:lower]  # make sure both lists are only up to the shortest length.\n",
    "    sells = sells[:lower]  # make sure both lists are only up to the shortest length.\n",
    "\n",
    "    sequential_data = buys+sells  # add them together\n",
    "    random.shuffle(sequential_data)  # another shuffle, so the model doesn't get confused with all 1 class then the other.\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for seq, target in sequential_data:  # going over our new sequential data\n",
    "        X.append(seq)  # X is the sequences\n",
    "        y.append(target)  # y is the targets/labels (buys vs sell/notbuy)\n",
    "\n",
    "    return np.array(X), y  # return X and y...and make X a numpy array! ..import numpy as np\n",
    "\n",
    "# Uso de una cadena sin procesar para evitar errores de escape de unicode\n",
    "file_path = r\"C:\\Users\\CRISTIAN CHAVEZ\\Proyecto IA\\cripto\\crypto_data\\BTC-USD.csv\"\n",
    "\n",
    "# Leer el archivo inicial\n",
    "df = pd.read_csv(file_path, names=['time', 'low', 'high', 'open', 'close', 'volume'])\n",
    "\n",
    "# DataFrame principal vacío para almacenar todos los datos\n",
    "main_df = pd.DataFrame()\n",
    "\n",
    "# Las 4 criptomonedas que queremos considerar\n",
    "ratios = [\"BCH-USD\", \"BTC-USD\", \"ETH-USD\", \"LTC-USD\"]\n",
    "\n",
    "# Ruta base donde se encuentran los archivos de datos\n",
    "base_path = r\"C:\\Users\\CRISTIAN CHAVEZ\\Proyecto IA\\cripto\\crypto_data\"\n",
    "\n",
    "# Iterar sobre cada ratio\n",
    "for ratio in ratios:\n",
    "    print(ratio)\n",
    "    \n",
    "    # Obtener la ruta completa al archivo\n",
    "    dataset = os.path.join(base_path, f\"{ratio}.csv\")\n",
    "    \n",
    "    # Leer el archivo específico\n",
    "    df = pd.read_csv(dataset, names=['time', 'low', 'high', 'open', 'close', 'volume'])\n",
    "    \n",
    "    # Renombrar columnas de 'close' y 'volume' para incluir el ticker\n",
    "    df.rename(columns={\"close\": f\"{ratio}_close\", \"volume\": f\"{ratio}_volume\"}, inplace=True)\n",
    "    \n",
    "    # Establecer 'time' como índice para poder unirlos por este tiempo compartido\n",
    "    df.set_index(\"time\", inplace=True)\n",
    "    \n",
    "    # Ignorar otras columnas además de 'close' y 'volume'\n",
    "    df = df[[f\"{ratio}_close\", f\"{ratio}_volume\"]]\n",
    "    \n",
    "    # Si el DataFrame principal está vacío, simplemente asignar el DataFrame actual\n",
    "    if len(main_df) == 0:\n",
    "        main_df = df\n",
    "    else:\n",
    "        # De lo contrario, unir estos datos con el DataFrame principal\n",
    "        main_df = main_df.join(df)\n",
    "\n",
    "# Crear una nueva columna 'future' que es el valor de cierre futuro desplazado por 'FUTURE_PERIOD_PREDICT'\n",
    "main_df['future'] = main_df[f'{RATIO_TO_PREDICT}_close'].shift(-FUTURE_PERIOD_PREDICT)\n",
    "\n",
    "# Crear una columna 'target' que clasifica si el valor futuro es mayor que el valor actual\n",
    "main_df['target'] = list(map(classify, main_df[f'{RATIO_TO_PREDICT}_close'], main_df['future']))\n",
    "\n",
    "main_df.dropna(inplace=True)\n",
    "\n",
    "# Imprimir las primeras filas del DataFrame resultante\n",
    "#print(main_df.head())\n",
    "\n",
    "times = sorted(main_df.index.values)  # get the times\n",
    "last_5pct = sorted(main_df.index.values)[-int(0.05*len(times))]  # get the last 5% of the times\n",
    "print(last_5pct)\n",
    "validation_main_df = main_df[(main_df.index >= last_5pct)]  # make the validation data where the index is in the last 5%\n",
    "main_df = main_df[(main_df.index < last_5pct)]  # now the main_df is all the data up to the last 5%train_x, train_y = preprocess_df(main_df) \n",
    "\n",
    "train_x, train_y = preprocess_df(main_df)\n",
    "validation_x, validation_y = preprocess_df(validation_main_df)\n",
    "print(f\"train data: {len(train_x)} validation: {len(validation_x)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15f15129-4a84-4a0b-802f-071be0403b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: 79774 validation: 4042\n",
      "Dont buys: 39887, buys: 39887\n",
      "VALIDATION Dont buys: 2021, buys: 2021\n"
     ]
    }
   ],
   "source": [
    "print(f\"train data: {len(train_x)} validation: {len(validation_x)}\")\n",
    "print(f\"Dont buys: {train_y.count(0)}, buys: {train_y.count(1)}\")\n",
    "print(f\"VALIDATION Dont buys: {validation_y.count(0)}, buys: {validation_y.count(1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585d17e1-f624-4e2a-9055-981e646bbec7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

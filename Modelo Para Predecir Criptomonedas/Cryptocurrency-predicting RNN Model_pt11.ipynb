{
 "cells": [
  {
   "cell_type": "raw",
   "id": "be7c168f-a89a-4980-be54-dff24740d827",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from collections import deque\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import requests\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization, Input\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "SEQ_LEN = 60\n",
    "FUTURE_PERIOD_PREDICT = 8\n",
    "RATIO_TO_PREDICT = \"bitcoin\"\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "NAME = f\"{RATIO_TO_PREDICT}-{SEQ_LEN}-SEQ-{FUTURE_PERIOD_PREDICT}-PRED-{int(time.time())}\"\n",
    "\n",
    "def classify(current, future):\n",
    "    return int(float(future) > float(current))\n",
    "\n",
    "def preprocess_df(df, balance_classes=True):\n",
    "    df = df.drop([\"future\"], axis=1)\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col != \"target\":\n",
    "            df[col] = df[col].pct_change()\n",
    "            df.dropna(inplace=True)\n",
    "            if df[col].empty:\n",
    "                print(f\"Advertencia: La columna {col} está vacía después de aplicar pct_change y eliminar NaNs.\")\n",
    "                continue\n",
    "            df[col] = preprocessing.scale(df[col].values)\n",
    "\n",
    "    # Modificación: agrega una condición para evitar NaN en la columna 'target'\n",
    "    df.dropna(subset=['target'], inplace=True)\n",
    "\n",
    "    sequential_data = []\n",
    "    prev_days = deque(maxlen=SEQ_LEN)\n",
    "\n",
    "    for i in df.values:\n",
    "        prev_days.append([n for n in i[:-1]])\n",
    "        if len(prev_days) == SEQ_LEN:\n",
    "            sequential_data.append([np.array(prev_days), i[-1]])\n",
    "\n",
    "    random.shuffle(sequential_data)\n",
    "\n",
    "    if balance_classes:\n",
    "        buys = [seq for seq in sequential_data if seq[1] == 1]\n",
    "        sells = [seq for seq in sequential_data if seq[1] == 0]\n",
    "\n",
    "        if len(buys) == 0 or len(sells) == 0:\n",
    "            raise ValueError(\"No hay suficientes datos de compra o venta para balancear las clases.\")\n",
    "\n",
    "        random.shuffle(buys)\n",
    "        random.shuffle(sells)\n",
    "\n",
    "        lower = min(len(buys), len(sells))\n",
    "\n",
    "        buys = buys[:lower]\n",
    "        sells = sells[:lower]\n",
    "\n",
    "        sequential_data = buys + sells\n",
    "        random.shuffle(sequential_data)\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for seq, target in sequential_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def get_crypto_data(crypto_id, days):\n",
    "    url = f\"https://api.coingecko.com/api/v3/coins/{crypto_id}/market_chart\"\n",
    "    params = {\n",
    "        'vs_currency': 'usd',\n",
    "        'days': days\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "\n",
    "    if 'prices' not in data:\n",
    "        print(f\"Advertencia: No se encontraron precios para {crypto_id}.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    prices = data['prices']\n",
    "    df = pd.DataFrame(prices, columns=['timestamp', 'price'])\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "ratios = [\"bitcoin\", \"dogecoin\", \"ethereum\", \"qtum\"]\n",
    "days = 365\n",
    "\n",
    "main_df = pd.DataFrame()\n",
    "\n",
    "for ratio in ratios:\n",
    "    print(ratio)\n",
    "    df = get_crypto_data(ratio, days)\n",
    "    if df.empty:\n",
    "        continue\n",
    "    df.rename(columns={\"price\": f\"{ratio}_close\"}, inplace=True)\n",
    "    if len(main_df) == 0:\n",
    "        main_df = df\n",
    "    else:\n",
    "        main_df = main_df.join(df, how='outer')\n",
    "\n",
    "print(main_df.columns)\n",
    "\n",
    "target_ratio = 'bitcoin_close'\n",
    "\n",
    "main_df['future'] = main_df[target_ratio].shift(-FUTURE_PERIOD_PREDICT)\n",
    "main_df['target'] = list(map(classify, main_df[target_ratio], main_df['future']))\n",
    "main_df.dropna(inplace=True)\n",
    "\n",
    "print(main_df.head())\n",
    "\n",
    "times = sorted(main_df.index.values)\n",
    "last_10pct = sorted(main_df.index.values)[-int(0.1 * len(times))]\n",
    "print(f\"Último 10% de los datos comienza en: {last_10pct}\")\n",
    "validation_main_df = main_df[main_df.index >= last_10pct]\n",
    "main_df = main_df[main_df.index < last_10pct]\n",
    "\n",
    "print(f\"Tamaño del conjunto de entrenamiento: {main_df.shape}\")\n",
    "print(f\"Tamaño del conjunto de validación: {validation_main_df.shape}\")\n",
    "\n",
    "train_x, train_y = preprocess_df(main_df)\n",
    "validation_x, validation_y = preprocess_df(validation_main_df, balance_classes=False)\n",
    "\n",
    "print(f\"train_x shape: {train_x.shape}\")\n",
    "print(f\"train_y shape: {train_y.shape}\")\n",
    "print(f\"validation_x shape: {validation_x.shape}\")\n",
    "print(f\"validation_y shape: {validation_y.shape}\")\n",
    "\n",
    "if validation_x.shape[0] == 0 or validation_y.shape[0] == 0:\n",
    "    print(\"Contenido de validation_main_df:\")\n",
    "    print(validation_main_df)\n",
    "    raise ValueError(\"El conjunto de datos de validación está vacío. Revisa los datos de entrada y el preprocesamiento.\")\n",
    "\n",
    "assert train_x.shape[1:] == (SEQ_LEN, train_x.shape[2]), f\"train_x shape incorrect: {train_x.shape}\"\n",
    "assert validation_x.shape[1:] == (SEQ_LEN, validation_x.shape[2]), f\"validation_x shape incorrect: {validation_x.shape}\"\n",
    "\n",
    "print(f\"train data: {len(train_x)} validation: {len(validation_x)}\")\n",
    "print(f\"Dont buys: {list(train_y).count(0)}, buys: {list(train_y).count(1)}\")\n",
    "print(f\"VALIDATION Dont buys: {list(validation_y).count(0)}, buys: {list(validation_y).count(1)}\")\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(SEQ_LEN, train_x.shape[2])),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    BatchNormalization(),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    Dropout(0.1),\n",
    "    BatchNormalization(),\n",
    "    LSTM(128),\n",
    "    Dropout(0.2),\n",
    "    BatchNormalization(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(  \n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=f\"logs/{NAME}\")\n",
    "checkpoint = ModelCheckpoint(f\"models/{NAME}-{{epoch:02d}}-{{val_accuracy:.3f}}.keras\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "history = model.fit(\n",
    "    train_x, train_y,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(validation_x, validation_y),\n",
    "    callbacks=[tensorboard, checkpoint],\n",
    ")\n",
    "\n",
    "print(f\"Modelo entrenado: {NAME}\")\n",
    "print(f\"Historia del entrenamiento: {history.history}\")\n",
    "\n",
    "# Evaluación del modelo en el conjunto de validación\n",
    "validation_loss, validation_acc = model.evaluate(validation_x, validation_y)\n",
    "print(f\"Pérdida en validación: {validation_loss}\")\n",
    "print(f\"Precisión en validación: {validation_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fb2d77-f711-4218-b2b3-02cc39b5d361",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
